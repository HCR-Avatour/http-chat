# HTTP Chat: Local hosted LLM chat

## Description
This project contains the resourses to locally deploy a Docker container that hosts a LLama 2 13b chat model onto the Nvidia Jetson Orin edge computing device. The project will deploy a chatroom API which is called upon by the [Speech_Pipeline](https://github.com/HCR-Avatour/Speech_pipeline)  repo to impletent the AI assistant interface for the Avatour project.

